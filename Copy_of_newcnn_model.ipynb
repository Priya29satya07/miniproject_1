{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priya29satya07/miniproject_1/blob/main/Copy_of_newcnn_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NjReQdeD8Rqy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "metadata": {
        "id": "f5QV9o-o8i2t"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
        "    return f1_val"
      ],
      "metadata": {
        "id": "TII7ppec8yE4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "c7RrB84f_JDJ",
        "outputId": "4510c0f3-45bc-4f05-ac09-c9787dd148da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# Data Preparation\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/covid-qu-ex dataset/Infection Segmentation Data/Infection Segmentation Data/Train',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/covid-qu-ex dataset/Infection Segmentation Data/Infection Segmentation Data/Val',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7LFEDrRc8Fr",
        "outputId": "d06f93fc-1142-4a70-c0f7-f8a9a8054c20"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8964 images belonging to 3 classes.\n",
            "Found 557 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = 'Custom_Model/'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# Define a ModelCheckpoint callback to save the model at every improved epoch\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=os.path.join(checkpoint_dir, 'model_epoch_{epoch:02d}_train_acc_{accuracy:.4f}_val_acc_{val_accuracy:.4f}.h5'),\n",
        "    monitor='val_accuracy',  # metric to monitor\n",
        "    verbose=1,  # verbosity - 0 or 1\n",
        "    save_best_only=True,  # Save only the best model according to the monitored metric\n",
        "    mode='max',  # Since we are monitoring accuracy, higher is better\n",
        "    save_weights_only=False  # Save the full model, not just the weights\n",
        ")\n",
        "\n",
        "# Create a custom CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(256, 256, 3), activation='relu'))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (1, 1), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu', name='fc1'))\n",
        "model.add(Dense(32, activation='relu', name='fc2'))\n",
        "model.add(Dense(3, activation='softmax'))  # Assuming 3 classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_score])\n",
        "\n",
        "# Adjust the `workers` parameter as necessary\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator),\n",
        "    callbacks=[checkpoint],\n",
        "    use_multiprocessing=True,  # Enable multiprocessing\n",
        "    workers=6  # Number of workers to use. Adjust as per your CPU cores.\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3_b6ZWAErZ3",
        "outputId": "5700d0b1-3fa7-44ad-f3a1-e7b69147fcf6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.8528 - accuracy: 0.5833 - f1_score: 0.4963\n",
            "Epoch 1: val_accuracy improved from -inf to 0.50090, saving model to Custom_Model/model_epoch_01_train_acc_0.5833_val_acc_0.5009.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r281/281 [==============================] - 481s 2s/step - loss: 0.8528 - accuracy: 0.5833 - f1_score: 0.4963 - val_loss: 1.0310 - val_accuracy: 0.5009 - val_f1_score: 0.0692\n",
            "Epoch 2/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.7453 - accuracy: 0.6283 - f1_score: 0.5738\n",
            "Epoch 2: val_accuracy did not improve from 0.50090\n",
            "281/281 [==============================] - 191s 658ms/step - loss: 0.7453 - accuracy: 0.6283 - f1_score: 0.5738 - val_loss: 1.0909 - val_accuracy: 0.4596 - val_f1_score: 0.0000e+00\n",
            "Epoch 3/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.7011 - accuracy: 0.6570 - f1_score: 0.6255\n",
            "Epoch 3: val_accuracy improved from 0.50090 to 0.55296, saving model to Custom_Model/model_epoch_03_train_acc_0.6570_val_acc_0.5530.h5\n",
            "281/281 [==============================] - 192s 672ms/step - loss: 0.7011 - accuracy: 0.6570 - f1_score: 0.6255 - val_loss: 0.9718 - val_accuracy: 0.5530 - val_f1_score: 0.3945\n",
            "Epoch 4/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.6640 - accuracy: 0.6740 - f1_score: 0.6529\n",
            "Epoch 4: val_accuracy improved from 0.55296 to 0.56194, saving model to Custom_Model/model_epoch_04_train_acc_0.6740_val_acc_0.5619.h5\n",
            "281/281 [==============================] - 188s 656ms/step - loss: 0.6640 - accuracy: 0.6740 - f1_score: 0.6529 - val_loss: 0.9308 - val_accuracy: 0.5619 - val_f1_score: 0.4783\n",
            "Epoch 5/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.6545 - accuracy: 0.6764 - f1_score: 0.6515\n",
            "Epoch 5: val_accuracy improved from 0.56194 to 0.56553, saving model to Custom_Model/model_epoch_05_train_acc_0.6764_val_acc_0.5655.h5\n",
            "281/281 [==============================] - 191s 666ms/step - loss: 0.6545 - accuracy: 0.6764 - f1_score: 0.6515 - val_loss: 0.9488 - val_accuracy: 0.5655 - val_f1_score: 0.4437\n",
            "Epoch 6/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.6095 - accuracy: 0.6967 - f1_score: 0.6865\n",
            "Epoch 6: val_accuracy improved from 0.56553 to 0.60682, saving model to Custom_Model/model_epoch_06_train_acc_0.6967_val_acc_0.6068.h5\n",
            "281/281 [==============================] - 185s 645ms/step - loss: 0.6095 - accuracy: 0.6967 - f1_score: 0.6865 - val_loss: 0.9068 - val_accuracy: 0.6068 - val_f1_score: 0.5262\n",
            "Epoch 7/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.5866 - accuracy: 0.7102 - f1_score: 0.6986\n",
            "Epoch 7: val_accuracy improved from 0.60682 to 0.68582, saving model to Custom_Model/model_epoch_07_train_acc_0.7102_val_acc_0.6858.h5\n",
            "281/281 [==============================] - 192s 671ms/step - loss: 0.5866 - accuracy: 0.7102 - f1_score: 0.6986 - val_loss: 0.7334 - val_accuracy: 0.6858 - val_f1_score: 0.6496\n",
            "Epoch 8/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.5548 - accuracy: 0.7232 - f1_score: 0.7145\n",
            "Epoch 8: val_accuracy did not improve from 0.68582\n",
            "281/281 [==============================] - 194s 672ms/step - loss: 0.5548 - accuracy: 0.7232 - f1_score: 0.7145 - val_loss: 0.7392 - val_accuracy: 0.6804 - val_f1_score: 0.6706\n",
            "Epoch 9/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.5423 - accuracy: 0.7295 - f1_score: 0.7185\n",
            "Epoch 9: val_accuracy improved from 0.68582 to 0.69120, saving model to Custom_Model/model_epoch_09_train_acc_0.7295_val_acc_0.6912.h5\n",
            "281/281 [==============================] - 187s 655ms/step - loss: 0.5423 - accuracy: 0.7295 - f1_score: 0.7185 - val_loss: 0.7303 - val_accuracy: 0.6912 - val_f1_score: 0.6748\n",
            "Epoch 10/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.5130 - accuracy: 0.7435 - f1_score: 0.7360\n",
            "Epoch 10: val_accuracy improved from 0.69120 to 0.69659, saving model to Custom_Model/model_epoch_10_train_acc_0.7435_val_acc_0.6966.h5\n",
            "281/281 [==============================] - 187s 646ms/step - loss: 0.5130 - accuracy: 0.7435 - f1_score: 0.7360 - val_loss: 0.7621 - val_accuracy: 0.6966 - val_f1_score: 0.6913\n",
            "Epoch 11/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.4889 - accuracy: 0.7535 - f1_score: 0.7475\n",
            "Epoch 11: val_accuracy improved from 0.69659 to 0.72352, saving model to Custom_Model/model_epoch_11_train_acc_0.7535_val_acc_0.7235.h5\n",
            "281/281 [==============================] - 184s 640ms/step - loss: 0.4889 - accuracy: 0.7535 - f1_score: 0.7475 - val_loss: 0.7113 - val_accuracy: 0.7235 - val_f1_score: 0.7146\n",
            "Epoch 12/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.4735 - accuracy: 0.7579 - f1_score: 0.7534\n",
            "Epoch 12: val_accuracy did not improve from 0.72352\n",
            "281/281 [==============================] - 186s 647ms/step - loss: 0.4735 - accuracy: 0.7579 - f1_score: 0.7534 - val_loss: 0.7693 - val_accuracy: 0.7181 - val_f1_score: 0.7145\n",
            "Epoch 13/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.4660 - accuracy: 0.7647 - f1_score: 0.7587\n",
            "Epoch 13: val_accuracy did not improve from 0.72352\n",
            "281/281 [==============================] - 185s 648ms/step - loss: 0.4660 - accuracy: 0.7647 - f1_score: 0.7587 - val_loss: 0.6785 - val_accuracy: 0.7199 - val_f1_score: 0.7190\n",
            "Epoch 14/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.4353 - accuracy: 0.7778 - f1_score: 0.7767\n",
            "Epoch 14: val_accuracy improved from 0.72352 to 0.73788, saving model to Custom_Model/model_epoch_14_train_acc_0.7778_val_acc_0.7379.h5\n",
            "281/281 [==============================] - 185s 650ms/step - loss: 0.4353 - accuracy: 0.7778 - f1_score: 0.7767 - val_loss: 0.7125 - val_accuracy: 0.7379 - val_f1_score: 0.7280\n",
            "Epoch 15/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.4091 - accuracy: 0.7928 - f1_score: 0.7905\n",
            "Epoch 15: val_accuracy improved from 0.73788 to 0.74506, saving model to Custom_Model/model_epoch_15_train_acc_0.7928_val_acc_0.7451.h5\n",
            "281/281 [==============================] - 185s 639ms/step - loss: 0.4091 - accuracy: 0.7928 - f1_score: 0.7905 - val_loss: 0.7802 - val_accuracy: 0.7451 - val_f1_score: 0.7530\n",
            "Epoch 16/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.3925 - accuracy: 0.7980 - f1_score: 0.7945\n",
            "Epoch 16: val_accuracy did not improve from 0.74506\n",
            "281/281 [==============================] - 184s 644ms/step - loss: 0.3925 - accuracy: 0.7980 - f1_score: 0.7945 - val_loss: 0.7236 - val_accuracy: 0.7289 - val_f1_score: 0.7297\n",
            "Epoch 17/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.3753 - accuracy: 0.8111 - f1_score: 0.8092\n",
            "Epoch 17: val_accuracy improved from 0.74506 to 0.76302, saving model to Custom_Model/model_epoch_17_train_acc_0.8111_val_acc_0.7630.h5\n",
            "281/281 [==============================] - 182s 636ms/step - loss: 0.3753 - accuracy: 0.8111 - f1_score: 0.8092 - val_loss: 0.6842 - val_accuracy: 0.7630 - val_f1_score: 0.7621\n",
            "Epoch 18/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.3581 - accuracy: 0.8076 - f1_score: 0.8069\n",
            "Epoch 18: val_accuracy did not improve from 0.76302\n",
            "281/281 [==============================] - 185s 646ms/step - loss: 0.3581 - accuracy: 0.8076 - f1_score: 0.8069 - val_loss: 0.7790 - val_accuracy: 0.7271 - val_f1_score: 0.7362\n",
            "Epoch 19/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.3403 - accuracy: 0.8234 - f1_score: 0.8225\n",
            "Epoch 19: val_accuracy did not improve from 0.76302\n",
            "281/281 [==============================] - 188s 652ms/step - loss: 0.3403 - accuracy: 0.8234 - f1_score: 0.8225 - val_loss: 0.7686 - val_accuracy: 0.7325 - val_f1_score: 0.7304\n",
            "Epoch 20/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.3235 - accuracy: 0.8244 - f1_score: 0.8238\n",
            "Epoch 20: val_accuracy did not improve from 0.76302\n",
            "281/281 [==============================] - 187s 653ms/step - loss: 0.3235 - accuracy: 0.8244 - f1_score: 0.8238 - val_loss: 0.6902 - val_accuracy: 0.7504 - val_f1_score: 0.7562\n",
            "Epoch 21/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.3186 - accuracy: 0.8337 - f1_score: 0.8328\n",
            "Epoch 21: val_accuracy did not improve from 0.76302\n",
            "281/281 [==============================] - 182s 636ms/step - loss: 0.3186 - accuracy: 0.8337 - f1_score: 0.8328 - val_loss: 0.8380 - val_accuracy: 0.7469 - val_f1_score: 0.7443\n",
            "Epoch 22/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.2958 - accuracy: 0.8368 - f1_score: 0.8371\n",
            "Epoch 22: val_accuracy did not improve from 0.76302\n",
            "281/281 [==============================] - 184s 643ms/step - loss: 0.2958 - accuracy: 0.8368 - f1_score: 0.8371 - val_loss: 0.7952 - val_accuracy: 0.7325 - val_f1_score: 0.7280\n",
            "Epoch 23/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.2904 - accuracy: 0.8409 - f1_score: 0.8394\n",
            "Epoch 23: val_accuracy did not improve from 0.76302\n",
            "281/281 [==============================] - 187s 653ms/step - loss: 0.2904 - accuracy: 0.8409 - f1_score: 0.8394 - val_loss: 0.8564 - val_accuracy: 0.7433 - val_f1_score: 0.7365\n",
            "Epoch 24/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.2749 - accuracy: 0.8447 - f1_score: 0.8445\n",
            "Epoch 24: val_accuracy did not improve from 0.76302\n",
            "281/281 [==============================] - 196s 685ms/step - loss: 0.2749 - accuracy: 0.8447 - f1_score: 0.8445 - val_loss: 0.8469 - val_accuracy: 0.7325 - val_f1_score: 0.7373\n",
            "Epoch 25/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.2691 - accuracy: 0.8522 - f1_score: 0.8503\n",
            "Epoch 25: val_accuracy did not improve from 0.76302\n",
            "281/281 [==============================] - 176s 616ms/step - loss: 0.2691 - accuracy: 0.8522 - f1_score: 0.8503 - val_loss: 0.8656 - val_accuracy: 0.7307 - val_f1_score: 0.7291\n",
            "Epoch 26/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.2457 - accuracy: 0.8571 - f1_score: 0.8570\n",
            "Epoch 26: val_accuracy did not improve from 0.76302\n",
            "281/281 [==============================] - 182s 635ms/step - loss: 0.2457 - accuracy: 0.8571 - f1_score: 0.8570 - val_loss: 1.0203 - val_accuracy: 0.7415 - val_f1_score: 0.7424\n",
            "Epoch 27/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.2373 - accuracy: 0.8579 - f1_score: 0.8567\n",
            "Epoch 27: val_accuracy did not improve from 0.76302\n",
            "281/281 [==============================] - 182s 633ms/step - loss: 0.2373 - accuracy: 0.8579 - f1_score: 0.8567 - val_loss: 0.8246 - val_accuracy: 0.7522 - val_f1_score: 0.7467\n",
            "Epoch 28/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.8582 - f1_score: 0.8581\n",
            "Epoch 28: val_accuracy did not improve from 0.76302\n",
            "281/281 [==============================] - 184s 644ms/step - loss: 0.2362 - accuracy: 0.8582 - f1_score: 0.8581 - val_loss: 0.9988 - val_accuracy: 0.7540 - val_f1_score: 0.7568\n",
            "Epoch 29/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.2205 - accuracy: 0.8661 - f1_score: 0.8666\n",
            "Epoch 29: val_accuracy did not improve from 0.76302\n",
            "281/281 [==============================] - 182s 633ms/step - loss: 0.2205 - accuracy: 0.8661 - f1_score: 0.8666 - val_loss: 1.0858 - val_accuracy: 0.7379 - val_f1_score: 0.7411\n",
            "Epoch 30/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.2218 - accuracy: 0.8665 - f1_score: 0.8670\n",
            "Epoch 30: val_accuracy did not improve from 0.76302\n",
            "281/281 [==============================] - 201s 702ms/step - loss: 0.2218 - accuracy: 0.8665 - f1_score: 0.8670 - val_loss: 1.1691 - val_accuracy: 0.7217 - val_f1_score: 0.7246\n",
            "Epoch 31/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.2193 - accuracy: 0.8717 - f1_score: 0.8712\n",
            "Epoch 31: val_accuracy did not improve from 0.76302\n",
            "281/281 [==============================] - 183s 634ms/step - loss: 0.2193 - accuracy: 0.8717 - f1_score: 0.8712 - val_loss: 1.0785 - val_accuracy: 0.7289 - val_f1_score: 0.7275\n",
            "Epoch 32/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.2244 - accuracy: 0.8688 - f1_score: 0.8673\n",
            "Epoch 32: val_accuracy did not improve from 0.76302\n",
            "281/281 [==============================] - 191s 668ms/step - loss: 0.2244 - accuracy: 0.8688 - f1_score: 0.8673 - val_loss: 1.5310 - val_accuracy: 0.7325 - val_f1_score: 0.7336\n",
            "Epoch 33/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.2116 - accuracy: 0.8696 - f1_score: 0.8691\n",
            "Epoch 33: val_accuracy did not improve from 0.76302\n",
            "281/281 [==============================] - 183s 638ms/step - loss: 0.2116 - accuracy: 0.8696 - f1_score: 0.8691 - val_loss: 1.1692 - val_accuracy: 0.7343 - val_f1_score: 0.7332\n",
            "Epoch 34/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.2047 - accuracy: 0.8708 - f1_score: 0.8712\n",
            "Epoch 34: val_accuracy did not improve from 0.76302\n",
            "281/281 [==============================] - 192s 662ms/step - loss: 0.2047 - accuracy: 0.8708 - f1_score: 0.8712 - val_loss: 1.2043 - val_accuracy: 0.7145 - val_f1_score: 0.7174\n",
            "Epoch 35/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.1918 - accuracy: 0.8810 - f1_score: 0.8804\n",
            "Epoch 35: val_accuracy improved from 0.76302 to 0.76661, saving model to Custom_Model/model_epoch_35_train_acc_0.8810_val_acc_0.7666.h5\n",
            "281/281 [==============================] - 187s 654ms/step - loss: 0.1918 - accuracy: 0.8810 - f1_score: 0.8804 - val_loss: 1.1184 - val_accuracy: 0.7666 - val_f1_score: 0.7669\n",
            "Epoch 36/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.8699 - f1_score: 0.8701\n",
            "Epoch 36: val_accuracy did not improve from 0.76661\n",
            "281/281 [==============================] - 196s 686ms/step - loss: 0.2279 - accuracy: 0.8699 - f1_score: 0.8701 - val_loss: 1.1171 - val_accuracy: 0.7056 - val_f1_score: 0.7024\n",
            "Epoch 37/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.2034 - accuracy: 0.8738 - f1_score: 0.8729\n",
            "Epoch 37: val_accuracy did not improve from 0.76661\n",
            "281/281 [==============================] - 194s 671ms/step - loss: 0.2034 - accuracy: 0.8738 - f1_score: 0.8729 - val_loss: 1.1927 - val_accuracy: 0.7397 - val_f1_score: 0.7338\n",
            "Epoch 38/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.1981 - accuracy: 0.8812 - f1_score: 0.8799\n",
            "Epoch 38: val_accuracy did not improve from 0.76661\n",
            "281/281 [==============================] - 187s 654ms/step - loss: 0.1981 - accuracy: 0.8812 - f1_score: 0.8799 - val_loss: 1.2652 - val_accuracy: 0.7253 - val_f1_score: 0.7250\n",
            "Epoch 39/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.1772 - accuracy: 0.8833 - f1_score: 0.8838\n",
            "Epoch 39: val_accuracy did not improve from 0.76661\n",
            "281/281 [==============================] - 188s 652ms/step - loss: 0.1772 - accuracy: 0.8833 - f1_score: 0.8838 - val_loss: 1.2503 - val_accuracy: 0.7451 - val_f1_score: 0.7467\n",
            "Epoch 40/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.1926 - accuracy: 0.8781 - f1_score: 0.8779\n",
            "Epoch 40: val_accuracy did not improve from 0.76661\n",
            "281/281 [==============================] - 187s 654ms/step - loss: 0.1926 - accuracy: 0.8781 - f1_score: 0.8779 - val_loss: 1.5387 - val_accuracy: 0.7127 - val_f1_score: 0.7129\n",
            "Epoch 41/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.2019 - accuracy: 0.8786 - f1_score: 0.8778\n",
            "Epoch 41: val_accuracy did not improve from 0.76661\n",
            "281/281 [==============================] - 182s 630ms/step - loss: 0.2019 - accuracy: 0.8786 - f1_score: 0.8778 - val_loss: 1.7617 - val_accuracy: 0.7127 - val_f1_score: 0.7083\n",
            "Epoch 42/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.1929 - accuracy: 0.8792 - f1_score: 0.8797\n",
            "Epoch 42: val_accuracy did not improve from 0.76661\n",
            "281/281 [==============================] - 180s 628ms/step - loss: 0.1929 - accuracy: 0.8792 - f1_score: 0.8797 - val_loss: 1.5447 - val_accuracy: 0.7235 - val_f1_score: 0.7202\n",
            "Epoch 43/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.1826 - accuracy: 0.8815 - f1_score: 0.8821\n",
            "Epoch 43: val_accuracy did not improve from 0.76661\n",
            "281/281 [==============================] - 188s 659ms/step - loss: 0.1826 - accuracy: 0.8815 - f1_score: 0.8821 - val_loss: 1.4331 - val_accuracy: 0.7379 - val_f1_score: 0.7390\n",
            "Epoch 44/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.8830 - f1_score: 0.8828\n",
            "Epoch 44: val_accuracy did not improve from 0.76661\n",
            "281/281 [==============================] - 197s 687ms/step - loss: 0.1755 - accuracy: 0.8830 - f1_score: 0.8828 - val_loss: 1.2288 - val_accuracy: 0.7343 - val_f1_score: 0.7168\n",
            "Epoch 45/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.1800 - accuracy: 0.8821 - f1_score: 0.8820\n",
            "Epoch 45: val_accuracy did not improve from 0.76661\n",
            "281/281 [==============================] - 181s 634ms/step - loss: 0.1800 - accuracy: 0.8821 - f1_score: 0.8820 - val_loss: 1.4826 - val_accuracy: 0.7110 - val_f1_score: 0.7136\n",
            "Epoch 46/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.1790 - accuracy: 0.8843 - f1_score: 0.8838\n",
            "Epoch 46: val_accuracy did not improve from 0.76661\n",
            "281/281 [==============================] - 181s 629ms/step - loss: 0.1790 - accuracy: 0.8843 - f1_score: 0.8838 - val_loss: 1.4905 - val_accuracy: 0.7307 - val_f1_score: 0.7407\n",
            "Epoch 47/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.1854 - accuracy: 0.8846 - f1_score: 0.8852\n",
            "Epoch 47: val_accuracy did not improve from 0.76661\n",
            "281/281 [==============================] - 199s 696ms/step - loss: 0.1854 - accuracy: 0.8846 - f1_score: 0.8852 - val_loss: 1.7232 - val_accuracy: 0.7127 - val_f1_score: 0.7140\n",
            "Epoch 48/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.1869 - accuracy: 0.8805 - f1_score: 0.8804\n",
            "Epoch 48: val_accuracy did not improve from 0.76661\n",
            "281/281 [==============================] - 201s 695ms/step - loss: 0.1869 - accuracy: 0.8805 - f1_score: 0.8804 - val_loss: 1.5998 - val_accuracy: 0.7325 - val_f1_score: 0.7370\n",
            "Epoch 49/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.1829 - accuracy: 0.8848 - f1_score: 0.8848\n",
            "Epoch 49: val_accuracy did not improve from 0.76661\n",
            "281/281 [==============================] - 188s 654ms/step - loss: 0.1829 - accuracy: 0.8848 - f1_score: 0.8848 - val_loss: 1.5629 - val_accuracy: 0.7002 - val_f1_score: 0.6989\n",
            "Epoch 50/50\n",
            "281/281 [==============================] - ETA: 0s - loss: 0.1768 - accuracy: 0.8868 - f1_score: 0.8859\n",
            "Epoch 50: val_accuracy did not improve from 0.76661\n",
            "281/281 [==============================] - 187s 650ms/step - loss: 0.1768 - accuracy: 0.8868 - f1_score: 0.8859 - val_loss: 1.6073 - val_accuracy: 0.7110 - val_f1_score: 0.7136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQaSvVnAD6QF",
        "outputId": "cb8455cb-d454-47d7-b2da-80dde69ade4d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 252, 252, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 126, 126, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 122, 122, 64)      51264     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 118, 118, 64)      102464    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 59, 59, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 59, 59, 128)       8320      \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 57, 57, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 53, 53, 128)       409728    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 86528)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 64)                5537856   \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 32)                2080      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6269539 (23.92 MB)\n",
            "Trainable params: 6269539 (23.92 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}