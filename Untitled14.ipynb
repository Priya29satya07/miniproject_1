{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOg0lYXk+RNp+r9rOiHSQoX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priya29satya07/miniproject_1/blob/main/Untitled14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PUpR0_akMKxp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "metadata": {
        "id": "T8GxtoTfMXuW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
        "    return f1_val"
      ],
      "metadata": {
        "id": "HwxDV49XMXkF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oecfMmRaMXdZ",
        "outputId": "902d3f4d-c16b-4dcf-c818-5d3274694272"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# Data Preparation\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.3\n",
        ")\n",
        "\n",
        "# Batch size\n",
        "batch_size = 16  # Experiment with different values\n",
        "\n",
        "# Training and validation generators with the new batch size\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/covid-qu-ex dataset/Infection Segmentation Data/Infection Segmentation Data/Train',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "   '/content/drive/MyDrive/covid-qu-ex dataset/Infection Segmentation Data/Infection Segmentation Data/Val',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "   subset='validation'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHP8Ig4uMXWj",
        "outputId": "5baa903a-9b7c-482b-954c-d22da0cabcdc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7845 images belonging to 3 classes.\n",
            "Found 837 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = 'Custom_Model/'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# Define a ModelCheckpoint callback to save the model at every improved epoch\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=os.path.join(checkpoint_dir, 'model_epoch_{epoch:02d}_train_acc_{accuracy:.4f}_val_acc_{val_accuracy:.4f}.h5'),\n",
        "    monitor='val_accuracy',  # metric to monitor\n",
        "    verbose=1,  # verbosity - 0 or 1\n",
        "    save_best_only=True,  # Save only the best model according to the monitored metric\n",
        "    mode='max',  # Since we are monitoring accuracy, higher is better\n",
        "    save_weights_only=False  # Save the full model, not just the weights\n",
        ")\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(256, 256, 3), activation='relu'))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (1, 1), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu', name='fc1'))\n",
        "model.add(Dense(32, activation='relu', name='fc2'))\n",
        "model.add(Dense(3, activation='softmax'))  # Assuming 3 classes\n",
        "\n",
        "# Adjust the learning rate\n",
        "custom_optimizer = Adam(learning_rate=0.0001)  # You can experiment with different values\n",
        "\n",
        "# Compile the model with the custom optimizer\n",
        "model.compile(optimizer=custom_optimizer, loss='categorical_crossentropy', metrics=['accuracy', f1_score])\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator),\n",
        "    callbacks=[checkpoint],\n",
        "    use_multiprocessing=True,\n",
        "    workers=6\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI7CzaMZMlRK",
        "outputId": "325227ad-9952-435b-80d6-3834495b1cf0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.9308 - accuracy: 0.5955 - f1_score: 0.4767\n",
            "Epoch 1: val_accuracy improved from -inf to 0.50060, saving model to Custom_Model/model_epoch_01_train_acc_0.5955_val_acc_0.5006.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r491/491 [==============================] - 276s 522ms/step - loss: 0.9308 - accuracy: 0.5955 - f1_score: 0.4767 - val_loss: 1.0506 - val_accuracy: 0.5006 - val_f1_score: 0.1202\n",
            "Epoch 2/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.8309 - accuracy: 0.6134 - f1_score: 0.5288\n",
            "Epoch 2: val_accuracy did not improve from 0.50060\n",
            "491/491 [==============================] - 185s 372ms/step - loss: 0.8309 - accuracy: 0.6134 - f1_score: 0.5288 - val_loss: 1.0445 - val_accuracy: 0.5006 - val_f1_score: 0.2626\n",
            "Epoch 3/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.7833 - accuracy: 0.6136 - f1_score: 0.5557\n",
            "Epoch 3: val_accuracy did not improve from 0.50060\n",
            "491/491 [==============================] - 180s 362ms/step - loss: 0.7833 - accuracy: 0.6136 - f1_score: 0.5557 - val_loss: 1.0379 - val_accuracy: 0.5006 - val_f1_score: 0.3590\n",
            "Epoch 4/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.7715 - accuracy: 0.6150 - f1_score: 0.5808\n",
            "Epoch 4: val_accuracy did not improve from 0.50060\n",
            "491/491 [==============================] - 194s 391ms/step - loss: 0.7715 - accuracy: 0.6150 - f1_score: 0.5808 - val_loss: 1.0556 - val_accuracy: 0.5006 - val_f1_score: 0.4673\n",
            "Epoch 5/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.7648 - accuracy: 0.6181 - f1_score: 0.5743\n",
            "Epoch 5: val_accuracy did not improve from 0.50060\n",
            "491/491 [==============================] - 183s 368ms/step - loss: 0.7648 - accuracy: 0.6181 - f1_score: 0.5743 - val_loss: 1.0469 - val_accuracy: 0.4994 - val_f1_score: 0.3148\n",
            "Epoch 6/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.7570 - accuracy: 0.6177 - f1_score: 0.5771\n",
            "Epoch 6: val_accuracy did not improve from 0.50060\n",
            "491/491 [==============================] - 196s 396ms/step - loss: 0.7570 - accuracy: 0.6177 - f1_score: 0.5771 - val_loss: 1.0522 - val_accuracy: 0.4958 - val_f1_score: 0.3610\n",
            "Epoch 7/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.7524 - accuracy: 0.6280 - f1_score: 0.5914\n",
            "Epoch 7: val_accuracy improved from 0.50060 to 0.51374, saving model to Custom_Model/model_epoch_07_train_acc_0.6280_val_acc_0.5137.h5\n",
            "491/491 [==============================] - 188s 379ms/step - loss: 0.7524 - accuracy: 0.6280 - f1_score: 0.5914 - val_loss: 1.0643 - val_accuracy: 0.5137 - val_f1_score: 0.0236\n",
            "Epoch 8/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.7423 - accuracy: 0.6254 - f1_score: 0.5878\n",
            "Epoch 8: val_accuracy did not improve from 0.51374\n",
            "491/491 [==============================] - 195s 393ms/step - loss: 0.7423 - accuracy: 0.6254 - f1_score: 0.5878 - val_loss: 1.0383 - val_accuracy: 0.5042 - val_f1_score: 0.4095\n",
            "Epoch 9/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.7226 - accuracy: 0.6296 - f1_score: 0.5892\n",
            "Epoch 9: val_accuracy did not improve from 0.51374\n",
            "491/491 [==============================] - 179s 359ms/step - loss: 0.7226 - accuracy: 0.6296 - f1_score: 0.5892 - val_loss: 1.0638 - val_accuracy: 0.5042 - val_f1_score: 0.1194\n",
            "Epoch 10/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.7240 - accuracy: 0.6328 - f1_score: 0.5949\n",
            "Epoch 10: val_accuracy did not improve from 0.51374\n",
            "491/491 [==============================] - 179s 361ms/step - loss: 0.7240 - accuracy: 0.6328 - f1_score: 0.5949 - val_loss: 1.0383 - val_accuracy: 0.5054 - val_f1_score: 0.4625\n",
            "Epoch 11/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.7048 - accuracy: 0.6409 - f1_score: 0.6025\n",
            "Epoch 11: val_accuracy improved from 0.51374 to 0.53405, saving model to Custom_Model/model_epoch_11_train_acc_0.6409_val_acc_0.5341.h5\n",
            "491/491 [==============================] - 194s 388ms/step - loss: 0.7048 - accuracy: 0.6409 - f1_score: 0.6025 - val_loss: 1.0223 - val_accuracy: 0.5341 - val_f1_score: 0.3895\n",
            "Epoch 12/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.7019 - accuracy: 0.6507 - f1_score: 0.6129\n",
            "Epoch 12: val_accuracy did not improve from 0.53405\n",
            "491/491 [==============================] - 179s 359ms/step - loss: 0.7019 - accuracy: 0.6507 - f1_score: 0.6129 - val_loss: 1.0448 - val_accuracy: 0.5006 - val_f1_score: 0.3782\n",
            "Epoch 13/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6863 - accuracy: 0.6538 - f1_score: 0.6252\n",
            "Epoch 13: val_accuracy did not improve from 0.53405\n",
            "491/491 [==============================] - 175s 354ms/step - loss: 0.6863 - accuracy: 0.6538 - f1_score: 0.6252 - val_loss: 1.0581 - val_accuracy: 0.5257 - val_f1_score: 0.4686\n",
            "Epoch 14/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6831 - accuracy: 0.6608 - f1_score: 0.6336\n",
            "Epoch 14: val_accuracy improved from 0.53405 to 0.54839, saving model to Custom_Model/model_epoch_14_train_acc_0.6608_val_acc_0.5484.h5\n",
            "491/491 [==============================] - 174s 352ms/step - loss: 0.6831 - accuracy: 0.6608 - f1_score: 0.6336 - val_loss: 1.0747 - val_accuracy: 0.5484 - val_f1_score: 0.4612\n",
            "Epoch 15/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6802 - accuracy: 0.6535 - f1_score: 0.6226\n",
            "Epoch 15: val_accuracy did not improve from 0.54839\n",
            "491/491 [==============================] - 191s 383ms/step - loss: 0.6802 - accuracy: 0.6535 - f1_score: 0.6226 - val_loss: 1.0296 - val_accuracy: 0.5400 - val_f1_score: 0.4726\n",
            "Epoch 16/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6753 - accuracy: 0.6562 - f1_score: 0.6280\n",
            "Epoch 16: val_accuracy did not improve from 0.54839\n",
            "491/491 [==============================] - 179s 361ms/step - loss: 0.6753 - accuracy: 0.6562 - f1_score: 0.6280 - val_loss: 1.0447 - val_accuracy: 0.4886 - val_f1_score: 0.3444\n",
            "Epoch 17/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6680 - accuracy: 0.6650 - f1_score: 0.6375\n",
            "Epoch 17: val_accuracy did not improve from 0.54839\n",
            "491/491 [==============================] - 176s 354ms/step - loss: 0.6680 - accuracy: 0.6650 - f1_score: 0.6375 - val_loss: 1.0255 - val_accuracy: 0.5388 - val_f1_score: 0.2917\n",
            "Epoch 18/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6621 - accuracy: 0.6668 - f1_score: 0.6392\n",
            "Epoch 18: val_accuracy did not improve from 0.54839\n",
            "491/491 [==============================] - 176s 354ms/step - loss: 0.6621 - accuracy: 0.6668 - f1_score: 0.6392 - val_loss: 1.0116 - val_accuracy: 0.5125 - val_f1_score: 0.4837\n",
            "Epoch 19/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6518 - accuracy: 0.6719 - f1_score: 0.6471\n",
            "Epoch 19: val_accuracy improved from 0.54839 to 0.55078, saving model to Custom_Model/model_epoch_19_train_acc_0.6719_val_acc_0.5508.h5\n",
            "491/491 [==============================] - 178s 357ms/step - loss: 0.6518 - accuracy: 0.6719 - f1_score: 0.6471 - val_loss: 1.0077 - val_accuracy: 0.5508 - val_f1_score: 0.3176\n",
            "Epoch 20/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6567 - accuracy: 0.6706 - f1_score: 0.6441\n",
            "Epoch 20: val_accuracy did not improve from 0.55078\n",
            "491/491 [==============================] - 177s 356ms/step - loss: 0.6567 - accuracy: 0.6706 - f1_score: 0.6441 - val_loss: 1.0223 - val_accuracy: 0.4970 - val_f1_score: 0.4942\n",
            "Epoch 21/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6535 - accuracy: 0.6751 - f1_score: 0.6533\n",
            "Epoch 21: val_accuracy did not improve from 0.55078\n",
            "491/491 [==============================] - 180s 363ms/step - loss: 0.6535 - accuracy: 0.6751 - f1_score: 0.6533 - val_loss: 0.9906 - val_accuracy: 0.5149 - val_f1_score: 0.4752\n",
            "Epoch 22/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6440 - accuracy: 0.6802 - f1_score: 0.6578\n",
            "Epoch 22: val_accuracy did not improve from 0.55078\n",
            "491/491 [==============================] - 183s 370ms/step - loss: 0.6440 - accuracy: 0.6802 - f1_score: 0.6578 - val_loss: 1.0025 - val_accuracy: 0.5341 - val_f1_score: 0.4992\n",
            "Epoch 23/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6446 - accuracy: 0.6788 - f1_score: 0.6611\n",
            "Epoch 23: val_accuracy did not improve from 0.55078\n",
            "491/491 [==============================] - 184s 371ms/step - loss: 0.6446 - accuracy: 0.6788 - f1_score: 0.6611 - val_loss: 0.9858 - val_accuracy: 0.5269 - val_f1_score: 0.4338\n",
            "Epoch 24/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6405 - accuracy: 0.6741 - f1_score: 0.6542\n",
            "Epoch 24: val_accuracy did not improve from 0.55078\n",
            "491/491 [==============================] - 184s 368ms/step - loss: 0.6405 - accuracy: 0.6741 - f1_score: 0.6542 - val_loss: 0.9673 - val_accuracy: 0.5508 - val_f1_score: 0.4863\n",
            "Epoch 25/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6401 - accuracy: 0.6829 - f1_score: 0.6623\n",
            "Epoch 25: val_accuracy did not improve from 0.55078\n",
            "491/491 [==============================] - 186s 375ms/step - loss: 0.6401 - accuracy: 0.6829 - f1_score: 0.6623 - val_loss: 0.9879 - val_accuracy: 0.5054 - val_f1_score: 0.4253\n",
            "Epoch 26/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6348 - accuracy: 0.6826 - f1_score: 0.6634\n",
            "Epoch 26: val_accuracy did not improve from 0.55078\n",
            "491/491 [==============================] - 181s 365ms/step - loss: 0.6348 - accuracy: 0.6826 - f1_score: 0.6634 - val_loss: 0.9754 - val_accuracy: 0.5412 - val_f1_score: 0.4214\n",
            "Epoch 27/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6365 - accuracy: 0.6752 - f1_score: 0.6570\n",
            "Epoch 27: val_accuracy did not improve from 0.55078\n",
            "491/491 [==============================] - 178s 358ms/step - loss: 0.6365 - accuracy: 0.6752 - f1_score: 0.6570 - val_loss: 0.9994 - val_accuracy: 0.5329 - val_f1_score: 0.3838\n",
            "Epoch 28/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6328 - accuracy: 0.6840 - f1_score: 0.6657\n",
            "Epoch 28: val_accuracy did not improve from 0.55078\n",
            "491/491 [==============================] - 192s 388ms/step - loss: 0.6328 - accuracy: 0.6840 - f1_score: 0.6657 - val_loss: 0.9754 - val_accuracy: 0.5436 - val_f1_score: 0.5293\n",
            "Epoch 29/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6392 - accuracy: 0.6786 - f1_score: 0.6585\n",
            "Epoch 29: val_accuracy did not improve from 0.55078\n",
            "491/491 [==============================] - 183s 368ms/step - loss: 0.6392 - accuracy: 0.6786 - f1_score: 0.6585 - val_loss: 0.9962 - val_accuracy: 0.5352 - val_f1_score: 0.4364\n",
            "Epoch 30/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6262 - accuracy: 0.6815 - f1_score: 0.6609\n",
            "Epoch 30: val_accuracy did not improve from 0.55078\n",
            "491/491 [==============================] - 183s 369ms/step - loss: 0.6262 - accuracy: 0.6815 - f1_score: 0.6609 - val_loss: 0.9728 - val_accuracy: 0.5185 - val_f1_score: 0.4235\n",
            "Epoch 31/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6272 - accuracy: 0.6863 - f1_score: 0.6647\n",
            "Epoch 31: val_accuracy did not improve from 0.55078\n",
            "491/491 [==============================] - 181s 365ms/step - loss: 0.6272 - accuracy: 0.6863 - f1_score: 0.6647 - val_loss: 0.9924 - val_accuracy: 0.5221 - val_f1_score: 0.5077\n",
            "Epoch 32/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6230 - accuracy: 0.6902 - f1_score: 0.6773\n",
            "Epoch 32: val_accuracy improved from 0.55078 to 0.55914, saving model to Custom_Model/model_epoch_32_train_acc_0.6902_val_acc_0.5591.h5\n",
            "491/491 [==============================] - 182s 368ms/step - loss: 0.6230 - accuracy: 0.6902 - f1_score: 0.6773 - val_loss: 0.9650 - val_accuracy: 0.5591 - val_f1_score: 0.4543\n",
            "Epoch 33/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6255 - accuracy: 0.6897 - f1_score: 0.6739\n",
            "Epoch 33: val_accuracy did not improve from 0.55914\n",
            "491/491 [==============================] - 182s 367ms/step - loss: 0.6255 - accuracy: 0.6897 - f1_score: 0.6739 - val_loss: 0.9837 - val_accuracy: 0.5137 - val_f1_score: 0.4946\n",
            "Epoch 34/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6224 - accuracy: 0.6836 - f1_score: 0.6673\n",
            "Epoch 34: val_accuracy did not improve from 0.55914\n",
            "491/491 [==============================] - 179s 360ms/step - loss: 0.6224 - accuracy: 0.6836 - f1_score: 0.6673 - val_loss: 1.0097 - val_accuracy: 0.4982 - val_f1_score: 0.4627\n",
            "Epoch 35/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6183 - accuracy: 0.6883 - f1_score: 0.6704\n",
            "Epoch 35: val_accuracy did not improve from 0.55914\n",
            "491/491 [==============================] - 181s 365ms/step - loss: 0.6183 - accuracy: 0.6883 - f1_score: 0.6704 - val_loss: 0.9638 - val_accuracy: 0.5544 - val_f1_score: 0.4714\n",
            "Epoch 36/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6209 - accuracy: 0.6872 - f1_score: 0.6671\n",
            "Epoch 36: val_accuracy did not improve from 0.55914\n",
            "491/491 [==============================] - 178s 357ms/step - loss: 0.6209 - accuracy: 0.6872 - f1_score: 0.6671 - val_loss: 0.9862 - val_accuracy: 0.5460 - val_f1_score: 0.5175\n",
            "Epoch 37/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6261 - accuracy: 0.6928 - f1_score: 0.6746\n",
            "Epoch 37: val_accuracy did not improve from 0.55914\n",
            "491/491 [==============================] - 195s 394ms/step - loss: 0.6261 - accuracy: 0.6928 - f1_score: 0.6746 - val_loss: 1.0066 - val_accuracy: 0.5042 - val_f1_score: 0.4576\n",
            "Epoch 38/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6115 - accuracy: 0.6966 - f1_score: 0.6787\n",
            "Epoch 38: val_accuracy did not improve from 0.55914\n",
            "491/491 [==============================] - 181s 366ms/step - loss: 0.6115 - accuracy: 0.6966 - f1_score: 0.6787 - val_loss: 0.9878 - val_accuracy: 0.5329 - val_f1_score: 0.4301\n",
            "Epoch 39/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6171 - accuracy: 0.6868 - f1_score: 0.6697\n",
            "Epoch 39: val_accuracy did not improve from 0.55914\n",
            "491/491 [==============================] - 196s 395ms/step - loss: 0.6171 - accuracy: 0.6868 - f1_score: 0.6697 - val_loss: 0.9687 - val_accuracy: 0.5568 - val_f1_score: 0.4678\n",
            "Epoch 40/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6176 - accuracy: 0.6878 - f1_score: 0.6724\n",
            "Epoch 40: val_accuracy did not improve from 0.55914\n",
            "491/491 [==============================] - 191s 385ms/step - loss: 0.6176 - accuracy: 0.6878 - f1_score: 0.6724 - val_loss: 0.9684 - val_accuracy: 0.5412 - val_f1_score: 0.4703\n",
            "Epoch 41/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6199 - accuracy: 0.6886 - f1_score: 0.6714\n",
            "Epoch 41: val_accuracy improved from 0.55914 to 0.56392, saving model to Custom_Model/model_epoch_41_train_acc_0.6886_val_acc_0.5639.h5\n",
            "491/491 [==============================] - 190s 383ms/step - loss: 0.6199 - accuracy: 0.6886 - f1_score: 0.6714 - val_loss: 0.9464 - val_accuracy: 0.5639 - val_f1_score: 0.4835\n",
            "Epoch 42/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6111 - accuracy: 0.7013 - f1_score: 0.6867\n",
            "Epoch 42: val_accuracy did not improve from 0.56392\n",
            "491/491 [==============================] - 186s 374ms/step - loss: 0.6111 - accuracy: 0.7013 - f1_score: 0.6867 - val_loss: 0.9990 - val_accuracy: 0.5436 - val_f1_score: 0.4116\n",
            "Epoch 43/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6159 - accuracy: 0.6927 - f1_score: 0.6783\n",
            "Epoch 43: val_accuracy did not improve from 0.56392\n",
            "491/491 [==============================] - 182s 366ms/step - loss: 0.6159 - accuracy: 0.6927 - f1_score: 0.6783 - val_loss: 0.9532 - val_accuracy: 0.5448 - val_f1_score: 0.5010\n",
            "Epoch 44/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6105 - accuracy: 0.6902 - f1_score: 0.6747\n",
            "Epoch 44: val_accuracy did not improve from 0.56392\n",
            "491/491 [==============================] - 184s 371ms/step - loss: 0.6105 - accuracy: 0.6902 - f1_score: 0.6747 - val_loss: 0.9670 - val_accuracy: 0.5400 - val_f1_score: 0.4787\n",
            "Epoch 45/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6095 - accuracy: 0.6952 - f1_score: 0.6823\n",
            "Epoch 45: val_accuracy did not improve from 0.56392\n",
            "491/491 [==============================] - 181s 365ms/step - loss: 0.6095 - accuracy: 0.6952 - f1_score: 0.6823 - val_loss: 0.9917 - val_accuracy: 0.5137 - val_f1_score: 0.4029\n",
            "Epoch 46/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6078 - accuracy: 0.6897 - f1_score: 0.6711\n",
            "Epoch 46: val_accuracy did not improve from 0.56392\n",
            "491/491 [==============================] - 177s 357ms/step - loss: 0.6078 - accuracy: 0.6897 - f1_score: 0.6711 - val_loss: 0.9632 - val_accuracy: 0.5603 - val_f1_score: 0.5334\n",
            "Epoch 47/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6150 - accuracy: 0.6899 - f1_score: 0.6753\n",
            "Epoch 47: val_accuracy did not improve from 0.56392\n",
            "491/491 [==============================] - 180s 361ms/step - loss: 0.6150 - accuracy: 0.6899 - f1_score: 0.6753 - val_loss: 0.9489 - val_accuracy: 0.5603 - val_f1_score: 0.4809\n",
            "Epoch 48/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6105 - accuracy: 0.6961 - f1_score: 0.6811\n",
            "Epoch 48: val_accuracy did not improve from 0.56392\n",
            "491/491 [==============================] - 188s 378ms/step - loss: 0.6105 - accuracy: 0.6961 - f1_score: 0.6811 - val_loss: 0.9621 - val_accuracy: 0.5556 - val_f1_score: 0.5123\n",
            "Epoch 49/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6071 - accuracy: 0.6960 - f1_score: 0.6774\n",
            "Epoch 49: val_accuracy did not improve from 0.56392\n",
            "491/491 [==============================] - 183s 366ms/step - loss: 0.6071 - accuracy: 0.6960 - f1_score: 0.6774 - val_loss: 0.9712 - val_accuracy: 0.5579 - val_f1_score: 0.4221\n",
            "Epoch 50/50\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.6008 - accuracy: 0.6941 - f1_score: 0.6813\n",
            "Epoch 50: val_accuracy did not improve from 0.56392\n",
            "491/491 [==============================] - 183s 366ms/step - loss: 0.6008 - accuracy: 0.6941 - f1_score: 0.6813 - val_loss: 0.9524 - val_accuracy: 0.5556 - val_f1_score: 0.5210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqZlFdgYMlK6",
        "outputId": "f5c6930c-99ce-42ae-ead9-01153055e2fb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 252, 252, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 126, 126, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 122, 122, 64)      51264     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 118, 118, 64)      102464    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 59, 59, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 59, 59, 128)       8320      \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 57, 57, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 53, 53, 128)       409728    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 86528)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 64)                5537856   \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 32)                2080      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6269539 (23.92 MB)\n",
            "Trainable params: 6269539 (23.92 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}